{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_own_assigment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XhY0i5XCm00Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440ec210-1829-4151-c4d4-62781f275fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path =  '/content/drive/MyDrive/ML_assignment3/'\n",
        "debug = 0"
      ],
      "metadata": {
        "id": "dLH5cGSlnAna"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install idx2numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEqm5Iou74hO",
        "outputId": "0156678c-f6cd-432f-ddf5-e65cadfd25fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: idx2numpy in /usr/local/lib/python3.7/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "def cal_loss(probs,N, y) : # probs -> last layer softmax output , N->size of last layer , y->label\n",
        "    \n",
        "\n",
        "    tmp = probs[np.arange(N), y]\n",
        "    qloss = random.uniform(0,1)\n",
        "    tmp = tmp[tmp != 0]\n",
        "    loss= 0\n",
        "    for x in tmp:\n",
        "      loss += (x*math.log(x))\n",
        "\n",
        "    loss = (-1)*loss\n",
        "    \n",
        "\n",
        "    return qloss\n",
        "\n",
        "    #  loss = -np.sum(np.log(probs[np.arange(N), y])) / N"
      ],
      "metadata": {
        "id": "1Hq4qaUPMQTS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "VhfiXxOW97fU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "essential function for using"
      ],
      "metadata": {
        "id": "6sCGVD4OuGto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def padding( X , pad ): # padding with zero\n",
        "   X_pad = np.pad(X , ((0,0),(pad,pad),(pad,pad),(0,0)),'constant',constant_values=0)\n",
        "   return X_pad"
      ],
      "metadata": {
        "id": "lUYSpKZQuGND"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Activation layer: implement an element-wise ReLU."
      ],
      "metadata": {
        "id": "E7i0UW08SyQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu( input):\n",
        "    input[input<0] = 0\n",
        "    return input\n",
        "\n",
        "def relu_derived(input):\n",
        "    input[input<0] = 0\n",
        "    input[input>0] = 1\n",
        "    return input"
      ],
      "metadata": {
        "id": "d9eI0Tk6SzYZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Softmax layer: it will convert final layer projections to normalized probabilities"
      ],
      "metadata": {
        "id": "HItPUWN_U9xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  softmax( input):\n",
        "           input = input - np.max( input , axis=0, keepdims=True)\n",
        "           return np.exp(input) / np.sum(np.exp(input), axis=0)\n"
      ],
      "metadata": {
        "id": "cmI3jaQ-U_AQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolution layer: there will be four (hyper)parameters: the number of output channels,filter dimension, stride, padding."
      ],
      "metadata": {
        "id": "wMy0JdurnGKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution_Layer:\n",
        "     def __init__(self ,name='conv', num_chanels = 6 , num_prev_chanels =1 , filter_size = 3 , stride = 1 , padding = 0 ,activation =None ):\n",
        "       self.num_chanels = num_chanels\n",
        "       self.num_prev_chanels = num_prev_chanels\n",
        "       self.filter_size = filter_size\n",
        "       self.stride = stride\n",
        "       self.padding = padding\n",
        "       self.W =  np.random.randn( filter_size ,filter_size , num_prev_chanels , num_chanels)\n",
        "       self.b = np.random.randn( 1,1,1,num_chanels)\n",
        "       self.last_input = None \n",
        "       self.activation = activation\n",
        "       self.name ='conv'\n",
        "\n",
        "\n",
        "     def forward(self, input ) : #input must be 4 by 4 matrix which is  output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "        \n",
        "        self.last_input = input #store for further using \n",
        "        (m, n_H_prev, n_W_prev, n_C_prev) = input.shape\n",
        "        (f_size, f_size, n_C_prev, n_C) = self.W.shape\n",
        "\n",
        "        # Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)\n",
        "        n_H = int((n_H_prev - f_size + 2 * self.padding) / self.stride) + 1\n",
        "        n_W = int((n_W_prev - f_size + 2 * self.padding) / self.stride) + 1\n",
        "        \n",
        "        # Initialize the output volume Z with zeros. (≈1 line)\n",
        "        Z = np.zeros((m, n_H, n_W, n_C))\n",
        "       \n",
        "        # Create input_pad by padding input\n",
        "        input_pad = padding(input, self.padding)\n",
        "       \n",
        "\n",
        "        for i in range(m):                               # loop over the batch of training examples\n",
        "            a_prev_pad = input_pad[i]                               # Select ith training example's padded activation\n",
        "            for h in range(n_H):\n",
        "                vert_start = h * self.stride\n",
        "                vert_end = vert_start + f_size                           # loop over vertical axis of the output volume\n",
        "                for w in range(n_W):  \n",
        "                    horiz_start = w * self.stride\n",
        "                    horiz_end = horiz_start + f_size                     # loop over horizontal axis of the output volume\n",
        "                    for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
        "                        \n",
        "                        # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                        \n",
        "                        # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
        "                        a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                        \n",
        "                        # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)            \n",
        "                        Z[i, h, w, c] = np.sum (np.multiply(a_slice_prev, self.W[...,c])) + float(self.b[...,c])\n",
        "                                           \n",
        "      \n",
        "        # Making sure your output shape is correct\n",
        "        assert(Z.shape == (m, n_H, n_W, n_C))  # delete this line of code\n",
        "        \n",
        "        if self.activation == 'Relu':\n",
        "           Z =relu(Z)\n",
        "        if debug == 1 : \n",
        "           print(' Inside convolution layer ->forward ')\n",
        "           print(Z.shape)\n",
        "        return Z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "     def backward(self,dZ):   #last layer data\n",
        "\n",
        "        \n",
        "        (m, n_H_prev, n_W_prev, n_C_prev) = self.last_input.shape\n",
        "        \n",
        "        # Retrieve dimensions from W's shape\n",
        "        (f_size, f_size, n_C_prev, n_C) = self.W.shape\n",
        "        \n",
        "        \n",
        "        # Retrieve dimensions from dZ's shape\n",
        "        (m, n_H, n_W, n_C) = dZ.shape\n",
        "        \n",
        "        # Initialize dA_prev, dW, db with the correct shapes\n",
        "        dA_prev = np.zeros(self.last_input.shape)                           \n",
        "        dW = np.zeros(self.W.shape)\n",
        "        db = np.zeros(self.b.shape)\n",
        "\n",
        "        # Pad A_prev and dA_prev\n",
        "        A_prev_pad = padding(self.last_input ,self.padding)\n",
        "        dA_prev_pad = padding(dA_prev , self.padding)\n",
        "        \n",
        "        for i in range(m):                       # loop over the training examples\n",
        "            \n",
        "            # select ith training example from A_prev_pad and dA_prev_pad\n",
        "            a_prev_pad = A_prev_pad[i]\n",
        "            da_prev_pad = dA_prev_pad[i]\n",
        "            \n",
        "            for h in range(n_H):                   # loop over vertical axis of the output volume\n",
        "                vert_start = h * self.stride\n",
        "                vert_end = vert_start + f_size\n",
        "                for w in range(n_W):               # loop over horizontal axis of the output volume\n",
        "                    horiz_start = w * self.stride\n",
        "                    horiz_end = horiz_start + f_size                      \n",
        "                    for c in range(n_C):           # loop over the channels of the output volume\n",
        "                        \n",
        "                        \n",
        "                        # Use the corners to define the slice from a_prev_pad\n",
        "                        a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "\n",
        "                        # Update gradients for the window and the filter's parameters using the code formulas given above\n",
        "                        da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += self.W[:,:,:,c] * dZ[i,h,w,c]\n",
        "                        dW[:,:,:,c] += a_slice *  dZ[i,h,w,c]\n",
        "                        db[:,:,:,c] += dZ[i,h,w,c]\n",
        "                        \n",
        "            # Set the ith training example's dA_prev to the unpadded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
        "            #print(i)\n",
        "            #print(da_prev_pad.shape)\n",
        "            if self.padding == 0: dA_prev[i,:,:,:] = da_prev_pad\n",
        "            else : dA_prev[i, :, :, :] = da_prev_pad[self.padding:(-1)*self.padding , self.padding:(-1)*self.padding,:]\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Making sure your output shape is correct\n",
        "        assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "\n",
        "        self.W -= dW * learning_rate\n",
        "        self.b -= db * learning_rate\n",
        "        if debug == 1 :\n",
        "           print(' Inside convolution layer-->backward ')\n",
        "           print(dA_prev.shape)\n",
        "        return dA_prev\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HNpsa4VQnKvZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Max-pooling layer: there will be two parameters: filter dimension, stride."
      ],
      "metadata": {
        "id": "DOPQn17VqrDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.lib.index_tricks import diag_indices_from\n",
        "class MaxPooling_Layer:\n",
        "     def __init__(self ,name='maxPool', filter_size = 2 , stride = 1 ) :\n",
        "\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.last_input = None\n",
        "        self.W = 0\n",
        "        self.b = 0\n",
        "        self.name = name\n",
        "\n",
        "     def forward( self , input ) :\n",
        "       \n",
        "        # Retrieve dimensions from the input shape\n",
        "        self.last_input = input\n",
        "        (m, n_H_prev, n_W_prev, n_C_prev) = input.shape\n",
        "        \n",
        "\n",
        "        # Define the dimensions of the output\n",
        "        n_H = int(1 + (n_H_prev - self.filter_size) / self.stride)\n",
        "        n_W = int(1 + (n_W_prev - self.filter_size) / self.stride)\n",
        "        n_C = n_C_prev\n",
        "        \n",
        "        # Initialize output matrix A\n",
        "        A = np.zeros((m, n_H, n_W, n_C))              \n",
        "        \n",
        "        ### START CODE HERE ###\n",
        "        for i in range(m):                         # loop over the training examples\n",
        "            for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
        "                vert_start = self.stride * h \n",
        "                vert_end = vert_start + self.filter_size\n",
        "                \n",
        "                for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                    # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
        "                    horiz_start = self.stride * w\n",
        "                    horiz_end = horiz_start + self.filter_size\n",
        "                    \n",
        "                    for c in range (n_C):            # loop over the channels of the output volume\n",
        "                        \n",
        "                        # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
        "                        a_prev_slice = input[i]\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice[vert_start:vert_end, horiz_start:horiz_end, c])\n",
        "                        \n",
        "\n",
        "        \n",
        "        # Making sure your output shape is correct\n",
        "        assert(A.shape == (m, n_H, n_W, n_C))\n",
        "        if debug == 1 : \n",
        "           print(' Inside MaxPooling layer->forward')\n",
        "           print(A.shape)\n",
        "        return A\n",
        "\n",
        "\n",
        "\n",
        "     def backward( self , input):   \n",
        "       \n",
        "          \n",
        "          \n",
        "          # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
        "          #print(input.shape)\n",
        "          m, n_H_prev, n_W_prev, n_C_prev = self.last_input.shape\n",
        "          m, n_H, n_W, n_C =input.shape\n",
        "          #print(self.last_input.shape)\n",
        "          \n",
        "          # Initialize dA_prev with zeros (≈1 line)\n",
        "          dA_prev = np.zeros(self.last_input.shape)\n",
        "          \n",
        "          for i in range(m):                       # loop over the training examples\n",
        "              \n",
        "              # select training example from A_prev (≈1 line)\n",
        "              a_prev = self.last_input[i]\n",
        "              da = input[i]\n",
        "              #print('da :',da.shape)\n",
        "                        \n",
        "              for h in range(n_H): \n",
        "                  vert_start = self.stride * h \n",
        "                  vert_end =  vert_start + self.filter_size                  # loop on the vertical axis\n",
        "                  for w in range(n_W):               # loop on the horizontal axis\n",
        "                      horiz_start = self.stride * w\n",
        "                      horiz_end = horiz_start + self.filter_size\n",
        "                      for c in range(n_C):           # loop over the channels (depth)\n",
        "                               \n",
        "                          # Use the corners and \"c\" to define the current slice from a_prev (≈1 line)\n",
        "                          a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                          # Create the mask from a_prev_slice (≈1 line)\n",
        "                          mask = ( a_prev_slice == (np.max(a_prev_slice)) ) \n",
        "                          #print('w:',w , 'h:', h)\n",
        "                          # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)\n",
        "                         \n",
        "                          dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += mask * da[h,w,c]\n",
        "                          \n",
        "                      \n",
        "          \n",
        "          # Making sure your output shape is correct\n",
        "          assert(dA_prev.shape == self.last_input.shape)\n",
        "          if debug == 1 : \n",
        "            print(' Inside MaxPooling layer->backward ')\n",
        "            print(dA_prev.shape)\n",
        "          return dA_prev"
      ],
      "metadata": {
        "id": "iiITemfMrAS_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fully-connected layer: a dense layer. There will be one parameter: output dimension."
      ],
      "metadata": {
        "id": "eVvsHy7idg7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnected_Layer:\n",
        "\n",
        "   def __init__( self ,name= 'fullyCon', nodes=100 , num_classes=10) : \n",
        "      self.W = np.random.randn(nodes , num_classes) \n",
        "      self.b = np.zeros(num_classes)\n",
        "      self.last_input = None\n",
        "      self.last_output = None\n",
        "      self.name = name\n",
        "\n",
        "   def forward( self , input) :\n",
        "      \n",
        "      (b,nh,nw,nc) = input.shape\n",
        "      self.last_input = input\n",
        "      #input = input.flatten()\n",
        "      input_flat = input.reshape(b,1,1,nh*nw*nc)\n",
        "      if debug == 1 :\n",
        "        print('inside fcl after flatten input ')\n",
        "        print(input_flat.shape)\n",
        "      output = np.dot(input_flat,self.W) + self.b\n",
        "      #self.last_input = input \n",
        "      self.last_output = output\n",
        "      #---------------------------flatting------------------------------------------------\n",
        "      (m , n_h , n_w , n_c) = output.shape\n",
        "\n",
        "      flatting_output = np.zeros(( m , n_h * n_w *n_c))\n",
        "      for i in range(m):\n",
        "        flatting_output[i] = softmax(output[i].flatten()) \n",
        "\n",
        "      if debug == 1 : \n",
        "        print(' Inside Fully connected layer-> forward')\n",
        "        print(flatting_output.shape)\n",
        "      return flatting_output\n",
        "\n",
        "   def backward(self,gradient): #gradient must be (32,10) size \n",
        "      N = self.last_input.shape[0]\n",
        "      new_input = self.last_input.reshape(N , -1)\n",
        "      dx = np.dot(gradient , self.W.T).reshape(self.last_input.shape)\n",
        "      dw = np.dot(new_input.T , gradient)\n",
        "      db = np.sum(gradient.T ,axis = 1)\n",
        "      self.W -= dw\n",
        "      self.b -= db\n",
        "      if debug == 1 :\n",
        "         print(' Inside Fully connected layer-> backword')\n",
        "         print(dx.shape)\n",
        "      return dx\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xQiDAOVIdpvq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN MODLE\n",
        "Conv 6 5 1 2 ->\n",
        "ReLU ->\n",
        "Pool 2 2 ->\n",
        "Conv 12 5 1 0 ->\n",
        "ReLU ->\n",
        "Pool 2 2 ->\n",
        "Conv 100 5 1 0 ->\n",
        "ReLU ->\n",
        "FC 10 ->\n",
        "Softmax"
      ],
      "metadata": {
        "id": "UwAT8V-pMb37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "class CNN:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "\n",
        "    def add_layer(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def build_model(self):\n",
        "        self.add_layer(Convolution_Layer( num_chanels = 6 , num_prev_chanels =1 , filter_size = 5 , stride = 1 , padding = 2 , activation = 'relu')) # for->minist dataset\n",
        "        # self.add_layer(Convolution_Layer( num_chanels = 6 , num_prev_chanels =3 , filter_size = 5 , stride = 1 , padding = 2 , activation = 'relu')) # for->ciphar dataset\n",
        "        self.add_layer(MaxPooling_Layer(filter_size = 2 , stride = 2 ))\n",
        "        self.add_layer(Convolution_Layer( num_chanels = 12 , num_prev_chanels =6 , filter_size = 5 , stride = 1 , padding = 0 , activation = 'relu'))\n",
        "        self.add_layer(MaxPooling_Layer(filter_size = 2 , stride = 2 ))\n",
        "        self.add_layer(Convolution_Layer( num_chanels = 100 , num_prev_chanels =12 , filter_size = 5 , stride = 1 , padding = 0 , activation = 'relu'))\n",
        "        self.add_layer(FullyConnected_Layer(nodes=100,num_classes=10)) #for ->minis dataset\n",
        "        # self.add_layer(FullyConnected_Layer(nodes=400,num_classes=10)) #for ->ciphar dataset\n",
        "    \n",
        "\n",
        "    def forward(self, input):                # forward propagate\n",
        "        for layer in self.layers:\n",
        "            input = layer.forward(input) #input size must be (32,28,28,1)\n",
        "            # print(layer.name)\n",
        "            # print(layer.last_input.shape)\n",
        "        return input\n",
        "\n",
        "    def backward(self, gradient):                # backward propagate\n",
        "        for layer in reversed(self.layers):\n",
        "            # print(layer.name)\n",
        "            # print(layer.last_input.shape)\n",
        "            gradient = layer.backward(gradient)\n",
        "\n",
        "    def train(self, dataset, num_epoch, verbose):\n",
        "        history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            print('\\n--- Epoch {0} ---'.format(epoch))\n",
        "            loss, tmp_loss, num_corr = 0, 0, 0\n",
        "            initial_time = time.time()\n",
        "            for i in range(0 , len(dataset['train_images']) , 32):\n",
        "            #for i in range(0 , 1280 , 32):\n",
        "                if i % 32 == 0:\n",
        "                    accuracy = (num_corr / (i + 1)) * 100       # compute training accuracy and loss up to iteration i\n",
        "                    misclassified = ((i - num_corr) / (i+1) ) \n",
        "                    #loss = tmp_loss / (i + 1)\n",
        "                    print('[batch %05d]: Loss %02.3f | Accuracy: %02.3f | Time: %02.2f seconds' %\n",
        "                          (int(i / 32), misclassified, accuracy, time.time() - initial_time))\n",
        "                                        \n",
        "                initial_time = time.time()\n",
        "\n",
        "                image = dataset['train_images'][i:i+32]\n",
        "                label = dataset['train_labels'][i:i+32]\n",
        "\n",
        "\n",
        "                tmp_output = self.forward(image)       # forward propagation\n",
        "\n",
        "                for eb in range(tmp_output.shape[0]):              \n",
        "                    if np.argmax(tmp_output[eb]) == label[eb]:                          # update accuracy\n",
        "                        num_corr += 1\n",
        "\n",
        "                loss = cal_loss(tmp_output , tmp_output.shape[0] , label)\n",
        "\n",
        "                dx = tmp_output/tmp_output.shape[0]\n",
        "                gradient =dx                                      # compute initial gradient\n",
        "                self.backward(gradient)                      # backward propagation\n",
        "\n",
        "        print('num_of_corr :',num_corr)\n",
        "        \n",
        "\n",
        "    def evaluate(self, X, y,  verbose):\n",
        "        loss, num_correct = 0, 0\n",
        "        for i in range(0,len(X),32):\n",
        "            tmp_output = self.forward(X[i:i+32])              # forward propagation\n",
        "            \n",
        "\n",
        "            # compute cross-entropy update loss\n",
        "            loss = cal_loss(tmp_output , tmp_output.shape[0] , y[i:i+32])\n",
        "            for eb in range(tmp_output.shape[0]):\n",
        "                prediction = np.argmax(tmp_output[eb])                              # update accuracy\n",
        "                if prediction == y[i+eb]:\n",
        "                    num_correct += 1\n",
        "\n",
        "\n",
        "        test_size = len(X)\n",
        "        accuracy = (num_correct / test_size) * 100\n",
        "        loss = (test_size-num_correct) / test_size\n",
        "        if verbose:\n",
        "            print('Test Loss: %02.3f' % loss)\n",
        "            print('Test Accuracy: %02.3f' % accuracy)\n",
        "        return loss, accuracy"
      ],
      "metadata": {
        "id": "T7QBbMEvMvcw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dataset_preparing"
      ],
      "metadata": {
        "id": "dLX-vqwJK4yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import idx2numpy\n",
        "import numpy as np\n",
        "from six.moves import cPickle\n",
        "import platform\n",
        "import cv2\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "\n",
        "def load_mnist():\n",
        "    X_train = idx2numpy.convert_from_file(base_path+'MNIST_data/train-images.idx3-ubyte')\n",
        "    train_labels = idx2numpy.convert_from_file(base_path+'MNIST_data/train-labels.idx1-ubyte')\n",
        "    X_test = idx2numpy.convert_from_file(base_path+'MNIST_data/t10k-images.idx3-ubyte')\n",
        "    test_labels = idx2numpy.convert_from_file(base_path+'MNIST_data/t10k-labels.idx1-ubyte')\n",
        "\n",
        "    train_images = []    \n",
        "    #print(X_train[0])\n",
        "    print(np.unique(train_labels))\n",
        "    print(X_train.shape)\n",
        "                                                   # reshape train images so that the training set\n",
        "    for i in range(X_train.shape[0]):                                   # is of shape (60000, 1, 28, 28)\n",
        "        train_images.append(np.expand_dims(X_train[i], axis=2))\n",
        "    train_images = np.array(train_images)\n",
        "    \n",
        "    #porced = input('input man:')\n",
        "\n",
        "    print(train_images.shape)\n",
        "    \n",
        "    test_images = []                                                    # reshape test images so that the test set\n",
        "    for i in range(X_test.shape[0]):                                    # is of shape (10000, 1, 28, 28)\n",
        "        test_images.append(np.expand_dims(X_test[i], axis=2))\n",
        "    test_images = np.array(test_images)\n",
        "    \n",
        "\n",
        "    indices = np.random.permutation(train_images.shape[0])              # permute and split training data in\n",
        "    training_idx, validation_idx = indices[:55000], indices[55000:]     # training and validation sets\n",
        "    train_images, validation_images = train_images[training_idx, :], train_images[validation_idx, :]\n",
        "    train_labels, validation_labels = train_labels[training_idx], train_labels[validation_idx]\n",
        "\n",
        "    return {\n",
        "        'train_images': train_images,\n",
        "        'train_labels': train_labels,\n",
        "        'validation_images': validation_images,\n",
        "        'validation_labels': validation_labels,\n",
        "        'test_images': test_images,\n",
        "        'test_labels': test_labels\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def minmax_normalize(x):\n",
        "    min_val = np.min(x)\n",
        "    max_val = np.max(x)\n",
        "    x = (x - min_val) / (max_val - min_val)\n",
        "    return x\n",
        "\n",
        "\n",
        "def preprocess(dataset):\n",
        "    dataset['train_images'] = np.array([minmax_normalize(x) for x in dataset['train_images']])\n",
        "    dataset['validation_images'] = np.array([minmax_normalize(x) for x in dataset['validation_images']])\n",
        "    dataset['test_images'] = np.array([minmax_normalize(x) for x in dataset['test_images']])\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "def load_pickle(f):\n",
        "    version = platform.python_version_tuple()\n",
        "    if version[0] == '2':\n",
        "        return cPickle.load(f)\n",
        "    elif version[0] == '3':\n",
        "        return cPickle.load(f, encoding='latin1')\n",
        "    raise ValueError(\"invalid python version: {}\".format(version))\n",
        "\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "    X_batch = []\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = load_pickle(f)\n",
        "        for i in range(datadict['data'].shape[0]):\n",
        "            X_batch.append(np.reshape(datadict['data'][i], (3, 32, 32)))\n",
        "        return np.array(X_batch), np.array(datadict['labels'])\n",
        "\n",
        "\n",
        "def load_cifar():\n",
        "    X_train, y_train = [], []\n",
        "    for batch in range(1, 6):\n",
        "        X_batch, y_batch = load_CIFAR_batch(os.path.join(base_path+'CIFAR_data', 'data_batch_%d' % batch))\n",
        "        X_train.append(X_batch)\n",
        "        y_train.append(y_batch)\n",
        "    X_train = np.concatenate(X_train)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    X_test, y_test = load_CIFAR_batch(os.path.join(base_path+'CIFAR_data', 'test_batch'))\n",
        "\n",
        "    indices = np.random.permutation(X_train.shape[0])                       # permute and split training data in\n",
        "    training_idx, validation_idx = indices[:49000], indices[49000:]         # training and validation sets\n",
        "    X_train, X_val = X_train[training_idx, :], X_train[validation_idx, :]\n",
        "    y_train, y_val = y_train[training_idx], y_train[validation_idx]\n",
        "    \n",
        "    print('different different shape : ')\n",
        "    X_train = X_train.transpose((0, 2, 3, 1))\n",
        "    X_test = X_test.transpose((0,2,3,1))\n",
        "    X_val =  X_val.transpose((0,2,3,1))\n",
        "    if debug == 1 :\n",
        "      print('inside load cifer dataset ')\n",
        "      print(X_train.shape)\n",
        "      print(X_test.shape)\n",
        "      print(X_val.shape)\n",
        "      print(y_train.shape)\n",
        "\n",
        "    return {\n",
        "        'train_images': X_train,\n",
        "        'train_labels': y_train,\n",
        "        'validation_images': X_val,\n",
        "        'validation_labels': y_val,\n",
        "        'test_images': X_test,\n",
        "        'test_labels': y_test\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KQknIqCVK4Lr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run code"
      ],
      "metadata": {
        "id": "zifSQ1ebLRRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'mnist'\n",
        "num_epochs = 1\n",
        "learning_rate = 0.01\n",
        "verbose = 1\n",
        "print('\\n--- Loading ' + dataset_name + ' dataset ---')               \n",
        "dataset = load_mnist() if dataset_name is 'mnist' else load_cifar()\n",
        "print('\\n--- Processing the dataset ---')                               \n",
        "dataset = preprocess(dataset)\n",
        "print('\\n--- Building the model ---')                                  \n",
        "model = CNN()\n",
        "model.build_model()\n",
        "print('\\n--- Training the model ---')                                   \n",
        "model.train(dataset,num_epochs,verbose)\n",
        "print('\\n--- Testing the model ---')                                    \n",
        "model.evaluate( dataset['test_images'],dataset['test_labels'],verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I99L9JACLS6p",
        "outputId": "c5150cee-b6ce-4b2a-dded-4a976b8aceb1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading mnist dataset ---\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "(60000, 28, 28)\n",
            "(60000, 28, 28, 1)\n",
            "\n",
            "--- Processing the dataset ---\n",
            "\n",
            "--- Building the model ---\n",
            "\n",
            "--- Training the model ---\n",
            "\n",
            "--- Epoch 1 ---\n",
            "[batch 00000]: Loss 0.000 | Accuracy: 0.000 | Time: 0.00 seconds\n",
            "[batch 00001]: Loss 0.909 | Accuracy: 6.061 | Time: 5.76 seconds\n",
            "[batch 00002]: Loss 0.908 | Accuracy: 7.692 | Time: 5.87 seconds\n",
            "[batch 00003]: Loss 0.897 | Accuracy: 9.278 | Time: 6.25 seconds\n",
            "[batch 00004]: Loss 0.915 | Accuracy: 7.752 | Time: 5.64 seconds\n",
            "[batch 00005]: Loss 0.913 | Accuracy: 8.075 | Time: 5.87 seconds\n",
            "[batch 00006]: Loss 0.907 | Accuracy: 8.808 | Time: 5.96 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: overflow encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[batch 00007]: Loss 0.916 | Accuracy: 8.000 | Time: 6.01 seconds\n",
            "[batch 00008]: Loss 0.918 | Accuracy: 7.782 | Time: 5.90 seconds\n",
            "[batch 00009]: Loss 0.917 | Accuracy: 7.958 | Time: 5.78 seconds\n",
            "[batch 00010]: Loss 0.910 | Accuracy: 8.723 | Time: 5.75 seconds\n",
            "[batch 00011]: Loss 0.909 | Accuracy: 8.782 | Time: 5.69 seconds\n",
            "[batch 00012]: Loss 0.912 | Accuracy: 8.571 | Time: 5.78 seconds\n",
            "[batch 00013]: Loss 0.914 | Accuracy: 8.393 | Time: 5.83 seconds\n",
            "[batch 00014]: Loss 0.911 | Accuracy: 8.686 | Time: 5.78 seconds\n",
            "[batch 00015]: Loss 0.904 | Accuracy: 9.356 | Time: 5.75 seconds\n",
            "[batch 00016]: Loss 0.904 | Accuracy: 9.357 | Time: 5.87 seconds\n",
            "[batch 00017]: Loss 0.897 | Accuracy: 10.092 | Time: 6.03 seconds\n",
            "[batch 00018]: Loss 0.896 | Accuracy: 10.225 | Time: 5.75 seconds\n",
            "[batch 00019]: Loss 0.898 | Accuracy: 10.016 | Time: 5.78 seconds\n",
            "[batch 00020]: Loss 0.899 | Accuracy: 9.984 | Time: 5.83 seconds\n",
            "[batch 00021]: Loss 0.899 | Accuracy: 9.955 | Time: 5.83 seconds\n",
            "[batch 00022]: Loss 0.898 | Accuracy: 10.071 | Time: 5.83 seconds\n",
            "[batch 00023]: Loss 0.898 | Accuracy: 10.041 | Time: 5.96 seconds\n",
            "[batch 00024]: Loss 0.901 | Accuracy: 9.753 | Time: 6.10 seconds\n",
            "[batch 00025]: Loss 0.900 | Accuracy: 9.863 | Time: 6.15 seconds\n",
            "[batch 00026]: Loss 0.899 | Accuracy: 9.964 | Time: 5.84 seconds\n",
            "[batch 00027]: Loss 0.898 | Accuracy: 10.058 | Time: 5.87 seconds\n",
            "[batch 00028]: Loss 0.900 | Accuracy: 9.922 | Time: 5.79 seconds\n",
            "[batch 00029]: Loss 0.898 | Accuracy: 10.118 | Time: 5.66 seconds\n",
            "[batch 00030]: Loss 0.899 | Accuracy: 9.990 | Time: 5.75 seconds\n",
            "[batch 00031]: Loss 0.899 | Accuracy: 9.970 | Time: 5.81 seconds\n",
            "[batch 00032]: Loss 0.899 | Accuracy: 10.049 | Time: 6.10 seconds\n",
            "[batch 00033]: Loss 0.900 | Accuracy: 9.934 | Time: 5.90 seconds\n",
            "[batch 00034]: Loss 0.899 | Accuracy: 10.009 | Time: 5.91 seconds\n",
            "[batch 00035]: Loss 0.898 | Accuracy: 10.080 | Time: 5.87 seconds\n",
            "[batch 00036]: Loss 0.899 | Accuracy: 9.974 | Time: 5.82 seconds\n",
            "[batch 00037]: Loss 0.900 | Accuracy: 9.958 | Time: 5.80 seconds\n",
            "[batch 00038]: Loss 0.901 | Accuracy: 9.778 | Time: 5.83 seconds\n",
            "[batch 00039]: Loss 0.902 | Accuracy: 9.688 | Time: 5.77 seconds\n",
            "[batch 00040]: Loss 0.902 | Accuracy: 9.680 | Time: 5.86 seconds\n",
            "[batch 00041]: Loss 0.903 | Accuracy: 9.596 | Time: 6.02 seconds\n",
            "[batch 00042]: Loss 0.903 | Accuracy: 9.665 | Time: 5.76 seconds\n",
            "[batch 00043]: Loss 0.903 | Accuracy: 9.659 | Time: 5.89 seconds\n",
            "[batch 00044]: Loss 0.903 | Accuracy: 9.652 | Time: 5.77 seconds\n",
            "[batch 00045]: Loss 0.903 | Accuracy: 9.646 | Time: 6.05 seconds\n",
            "[batch 00046]: Loss 0.900 | Accuracy: 9.912 | Time: 5.79 seconds\n",
            "[batch 00047]: Loss 0.900 | Accuracy: 9.900 | Time: 5.90 seconds\n",
            "[batch 00048]: Loss 0.902 | Accuracy: 9.759 | Time: 5.77 seconds\n",
            "[batch 00049]: Loss 0.902 | Accuracy: 9.688 | Time: 5.76 seconds\n",
            "[batch 00050]: Loss 0.903 | Accuracy: 9.681 | Time: 5.75 seconds\n",
            "[batch 00051]: Loss 0.903 | Accuracy: 9.614 | Time: 5.86 seconds\n",
            "[batch 00052]: Loss 0.903 | Accuracy: 9.670 | Time: 5.91 seconds\n",
            "[batch 00053]: Loss 0.902 | Accuracy: 9.723 | Time: 5.73 seconds\n",
            "[batch 00054]: Loss 0.903 | Accuracy: 9.601 | Time: 5.98 seconds\n",
            "[batch 00055]: Loss 0.903 | Accuracy: 9.654 | Time: 6.01 seconds\n",
            "[batch 00056]: Loss 0.904 | Accuracy: 9.593 | Time: 5.86 seconds\n",
            "[batch 00057]: Loss 0.904 | Accuracy: 9.589 | Time: 5.96 seconds\n",
            "[batch 00058]: Loss 0.905 | Accuracy: 9.478 | Time: 5.89 seconds\n",
            "[batch 00059]: Loss 0.905 | Accuracy: 9.476 | Time: 5.76 seconds\n",
            "[batch 00060]: Loss 0.905 | Accuracy: 9.474 | Time: 5.79 seconds\n",
            "[batch 00061]: Loss 0.904 | Accuracy: 9.575 | Time: 5.75 seconds\n",
            "[batch 00062]: Loss 0.905 | Accuracy: 9.471 | Time: 5.86 seconds\n",
            "[batch 00063]: Loss 0.906 | Accuracy: 9.370 | Time: 5.80 seconds\n",
            "[batch 00064]: Loss 0.906 | Accuracy: 9.322 | Time: 5.86 seconds\n",
            "[batch 00065]: Loss 0.907 | Accuracy: 9.274 | Time: 5.78 seconds\n",
            "[batch 00066]: Loss 0.907 | Accuracy: 9.276 | Time: 5.89 seconds\n",
            "[batch 00067]: Loss 0.907 | Accuracy: 9.231 | Time: 5.94 seconds\n",
            "[batch 00068]: Loss 0.908 | Accuracy: 9.187 | Time: 5.95 seconds\n",
            "[batch 00069]: Loss 0.908 | Accuracy: 9.144 | Time: 5.77 seconds\n",
            "[batch 00070]: Loss 0.909 | Accuracy: 9.014 | Time: 6.03 seconds\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f4fbd54dd2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n--- Training the model ---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n--- Testing the model ---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-814b60c0ba7a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, num_epoch, verbose)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_output\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtmp_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdx\u001b[0m                                      \u001b[0;31m# compute initial gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m# backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_of_corr :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_corr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-814b60c0ba7a>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# print(layer.name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# print(layer.last_input.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-8311550d196d>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dZ)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0;31m# Update gradients for the window and the filter's parameters using the code formulas given above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                         \u001b[0mda_prev_pad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvert_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvert_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhoriz_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhoriz_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                         \u001b[0mdW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma_slice\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0mdZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}